{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829f817b",
   "metadata": {},
   "source": [
    "# 1. BOW 기반 카운트 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9e5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c53e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/mkw/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e43d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#review count:  2000\n",
      "#samples of file ids:  ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print('#review count: ', len(movie_reviews.fileids()))\n",
    "print('#samples of file ids: ', movie_reviews.fileids()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7af13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#id of the first review:  neg/cv000_29416.txt\n",
      "\n",
      "#first review content: \n",
      " plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "w\n",
      "\n",
      "#sentence tokenization result:  [['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.']]\n",
      "\n",
      "#word tokenization result:  ['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an']\n"
     ]
    }
   ],
   "source": [
    "fileid = movie_reviews.fileids()[0]\n",
    "print('#id of the first review: ', fileid)\n",
    "print()\n",
    "print('#first review content: \\n', movie_reviews.raw(fileid)[:200])\n",
    "print()\n",
    "print('#sentence tokenization result: ', movie_reviews.sents(fileid)[:2])\n",
    "print()\n",
    "print('#word tokenization result: ', movie_reviews.words(fileid)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f412d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch']\n"
     ]
    }
   ],
   "source": [
    "documents = [list(movie_reviews.words(fileid)) for fileid in movie_reviews.fileids()]\n",
    "print(documents[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe34419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of ',': 77717, count of 'the': 76529, count of '.': 65876, count of 'a': 38106, count of 'and': 35576, count of 'of': 34123, count of 'to': 31937, count of ''': 30585, count of 'is': 25195, count of 'in': 21822, "
     ]
    }
   ],
   "source": [
    "word_count = {}\n",
    "for text in documents:\n",
    "    for word in text:\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "\n",
    "sorted_features = sorted(word_count, key = word_count.get, reverse = True)\n",
    "for word in sorted_features[:10]:\n",
    "    print(f\"count of '{word}': {word_count[word]}\", end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aadf7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608bea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of features:  43030\n",
      "count of 'film' : 8935, count of 'one' : 5791, count of 'movie' : 5538, count of 'like' : 3690, count of 'even' : 2564, count of 'time' : 2409, count of 'good' : 2407, count of 'story' : 2136, count of 'would' : 2084, count of 'much' : 2049, "
     ]
    }
   ],
   "source": [
    "documents = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
    "\n",
    "tokens = [[token for token in tokenizer.tokenize(doc) if token not in english_stops] for doc in documents]\n",
    "word_count = {}\n",
    "for text in tokens:\n",
    "    for word in text:\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "\n",
    "sorted_features = sorted(word_count, key = word_count.get, reverse = True)\n",
    "\n",
    "print('num of features: ', len(sorted_features))\n",
    "for word in sorted_features[:10]:\n",
    "    print(f\"count of '{word}' : {word_count[word]}\", end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df248d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = sorted_features[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "047dbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document, word_features):\n",
    "    word_count = {}\n",
    "    for word in document: #document에 있는 단어들에 대해 빈도수를 먼저 계산\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "        \n",
    "    features = []\n",
    "    for word in word_features: #word_features의 단어에 대해 계산된 빈도수를 feature에 추가\n",
    "        features.append(word_count.get(word, 0)) #빈도가 없는 단어는 0을 입력\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49ab245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "word_features_ex = ['one', 'two', 'teen', 'couples', 'solo']\n",
    "doc_ex = ['two', 'two', 'couples']\n",
    "print(document_features(doc_ex, word_features_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7944d916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(film, 5), (one, 3), (movie, 6), (like, 3), (even, 3), (time, 0), (good, 2), (story, 0), (would, 1), (much, 0), (also, 1), (get, 3), (character, 1), (two, 2), (well, 1), (first, 0), (characters, 1), (see, 2), (way, 3), (make, 5), "
     ]
    }
   ],
   "source": [
    "feature_sets = [document_features(d, word_features) for d in tokens]\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'({word_features[i]}, {feature_sets[0][i]})', end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cc92eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(feature_sets[0][-20:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
