{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a06fcb",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd136a",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c6494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 3219\n",
      "#Selected categories: ['alt.atheism', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'sci.crypt', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space',\n",
    "             'comp.sys.ibm.pc.hardware', 'sci.crypt']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train', categories = categories)\n",
    "\n",
    "print('#Train set size:', len(newsgroups_train.data))\n",
    "print('#Selected categories:', newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb333be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(token_pattern = \"[\\w']{3,}\", stop_words = 'english',\n",
    "                    max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "review_cv = cv.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ae443",
   "metadata": {},
   "source": [
    "- topic_word_prior (ùõΩ): ÌÜ†ÌîΩÏùò ÏÇ¨Ï†Ñ Îã®Ïñ¥ Î∂ÑÌè¨\n",
    "    - Î≥¥ÌÜµ 0.1\n",
    "- doc_topic_prior (ùõº): Î¨∏ÏÑúÏùò ÏÇ¨Ï†Ñ ÌÜ†ÌîΩ Î∂ÑÌè¨\n",
    "    - Î≥¥ÌÜµ 50/n_components\n",
    "- learning_method\n",
    "    - batch: ÏÑ±Îä• Ïö∞Ïàò, ÎäêÎ¶º\n",
    "    - online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca60fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#shape of review_topics:  (3219, 10)\n",
      "#Sample of review_topics:  [0.903 0.007 0.027 0.008 0.007 0.008 0.007 0.007 0.007 0.018]\n",
      "#Sum of topic weights of documents: [0.087 0.083 0.085 0.115 0.115 0.126 0.098 0.072 0.07  0.148]\n",
      "#shape of topic word distribution: (10, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "np.set_printoptions(precision = 3)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = 10,\n",
    "                               max_iter = 5,\n",
    "                               topic_word_prior = 0.1, doc_topic_prior = 1.0,\n",
    "                               learning_method = 'online',\n",
    "                               n_jobs = -1,\n",
    "                               random_state = 0)\n",
    "\n",
    "review_topics = lda.fit_transform(review_cv)\n",
    "print('#shape of review_topics: ', review_topics.shape)\n",
    "print('#Sample of review_topics: ', review_topics[0])\n",
    "\n",
    "gross_topic_weights = np.mean(review_topics, axis = 0)\n",
    "print('#Sum of topic weights of documents:', gross_topic_weights)\n",
    "print('#shape of topic word distribution:', lda.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60ee0071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: com, morality, keith, article, sgi, think, sandvik, objective, caltech, moral\n",
      "Topic #1: image, file, graphics, files, ftp, available, software, use, data, mail\n",
      "Topic #2: space, nasa, access, launch, earth, orbit, shuttle, digex, lunar, satellite\n",
      "Topic #3: article, com, just, don't, like, i'm, nntp, university, host, posting\n",
      "Topic #4: key, clipper, chip, encryption, com, government, law, keys, use, escrow\n",
      "Topic #5: scsi, com, bit, ibm, bus, know, windows, thanks, card, university\n",
      "Topic #6: host, gov, nntp, posting, university, distribution, nasa, ___, world, com\n",
      "Topic #7: drive, com, disk, hard, controller, drives, dos, tape, floppy, problem\n",
      "Topic #8: key, public, message, faq, mail, pgp, des, group, uni, ripem\n",
      "Topic #9: god, people, don't, jesus, believe, just, does, say, think, know\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print('Topic #%d: ' %topic_idx, end = '')\n",
    "        print(\", \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        # ÏúÑ slicingÏóêÏÑú Îß® Îí§ -1ÏùÄ Ïó≠ÏàúÏùÑ ÏùòÎØ∏, Ïó≠ÏàúÏúºÎ°ú ÌñàÏùÑ Îïå Ï≤òÏùåÎ∂ÄÌÑ∞ n_top_wordsÍπåÏßÄ\n",
    "    print()\n",
    "\n",
    "print_top_words(lda,cv.get_feature_names_out(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2b126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
