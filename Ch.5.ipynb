{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff14e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 2034\n",
      "#Test set size: 1353\n",
      "#Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "#Train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train',\n",
    "                                          remove = ('headers', 'footers', 'quotes'),\n",
    "                                          categories = categories)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test',\n",
    "                                          remove = ('headers', 'footers', 'quotes'),\n",
    "                                          categories = categories)\n",
    "\n",
    "print('#Train set size:', len(newsgroups_train.data))\n",
    "print('#Test set size:', len(newsgroups_test.data))\n",
    "print('#Selected categories:', newsgroups_train.target_names)\n",
    "print('#Train labels:', set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73e500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "#Train set label smaples: 1\n",
      "#Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "#Test set label smaples: 2\n"
     ]
    }
   ],
   "source": [
    "print('#Train set text samples:', newsgroups_train.data[0])\n",
    "print('#Train set label smaples:', newsgroups_train.target[0])\n",
    "print('#Test set text samples:', newsgroups_test.data[0])\n",
    "print('#Test set label smaples:', newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b75fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension:  (2034, 2000)\n",
      "Test set dimension:  (1353, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "print('Train set dimension: ', X_train_cv.shape)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "print('Test set dimension: ', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74df22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(cv.get_feature_names_out()[:100], X_train_cv[0].toarray()[0, :100]):\n",
    "    print(word, ':', count, end = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c9720",
   "metadata": {},
   "source": [
    "# 나이브 베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26977532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.824\n",
      "Test set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train))) \n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a161973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
      "#Second document and label in test data: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n"
     ]
    }
   ],
   "source": [
    "print('#First document and label in test data:', X_test[0], y_test[0])\n",
    "print('#Second document and label in test data:', X_test[1], y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3388c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Predicted labels:  [2 1]\n",
      "#Predicted categories: sci.space comp.graphics\n"
     ]
    }
   ],
   "source": [
    "pred = NB_clf.predict(X_test_cv[:2])\n",
    "print('#Predicted labels: ', pred)\n",
    "print('#Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6189a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.862\n",
      "Test set score: 0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 2000, max_df = 0.5, min_df = 5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) \n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d28c9536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
      "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
      "sci.space: space, on, you, be, was, this, as, they, have, are\n",
      "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkw/opt/anaconda3/envs/serv1/lib/python3.7/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top10_features(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names_out())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(-classifier.coef_[i])[:10]\n",
    "        print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
    "        # coef_ -> 로지스틱 회귀 분석에서 주로 사용할 것, sklearn에서 더 이상 지원X\n",
    "top10_features(NB_clf, tfidf, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0f422",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fab702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.930\n",
      "Test set score: 0.734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_clf = LogisticRegression()\n",
    "LR_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) \n",
    "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa6635",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b6ee43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.960\n",
      "Test set score: 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa1a4eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alpha 1.600 at max validation score 0.826\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(X_train_tfidf, y_train,\n",
    "                                                                         test_size = 0.2, random_state = 42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0.1, 10, 0.1): \n",
    "    ridge_clf = RidgeClassifier(alpha=alpha)\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge) \n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge) \n",
    "    if score > max_score: \n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb4aca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.948\n",
      "Test set score: 0.739\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha = 1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f63fc7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
      "comp.graphics: graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
      "sci.space: space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
      "talk.religion.misc: christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
     ]
    }
   ],
   "source": [
    "top10_features(ridge_clf, tfidf, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79849338",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "855efd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.819\n",
      "#Test set score: 0.724\n",
      "#Used features count: 437 out of 2000\n"
     ]
    }
   ],
   "source": [
    "lasso_clf = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = 1)\n",
    "\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 계수(coefficient) 중에서 0이 아닌 것들의 개수를 출력\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6b24ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice\n",
      "comp.graphics: graphics, image, 3d, file, computer, hi, video, files, looking, sphere\n",
      "sci.space: space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar\n",
      "talk.religion.misc: fbi, christian, christians, christ, order, jesus, children, objective, context, blood\n"
     ]
    }
   ],
   "source": [
    "top10_features(lasso_clf, tfidf, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531541b",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a7445fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.977\n",
      "#Decision Tree test set score: 0.536\n",
      "#Random Forest train set score: 0.977\n",
      "#Random Forest test set score: 0.685\n",
      "#Gradient Boosting train set score: 0.933\n",
      "#Gradient Boosting test set score: 0.696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(random_state=7)\n",
    "forest.fit(X_train_tfidf, y_train)\n",
    "print('#Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))\n",
    "print('#Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=7)\n",
    "gb.fit(X_train_tfidf, y_train)\n",
    "print('#Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))\n",
    "print('#Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62829290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, looking: 0.010, christian: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
     ]
    }
   ],
   "source": [
    "sorted_feature_importances = sorted(zip(tfidf.get_feature_names_out(), gb.feature_importances_),\n",
    "                                   key = lambda x: x[1],\n",
    "                                   reverse = True)\n",
    "\n",
    "for feature, value in sorted_feature_importances[:40]:\n",
    "    print('%s: %.3f' % (feature, value), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f005c4d",
   "metadata": {},
   "source": [
    "# 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb58ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "cachedStopWords = stopwords.words('english')\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\")\n",
    "english_stops = set(stopwords.words('english'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower())\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    features = (list(map(lambda token: PorterStemmer().stem(token), words)))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8760fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.930\n",
      "#Test set score: 0.751\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = tokenizer, max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "LR_clf = LogisticRegression()\n",
    "LR_clf.fit(X_train_tfidf, y_train) \n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) \n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e793c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set dimension: (2034, 20085)\n",
      "#Test set dimension: (1353, 20085)\n",
      "#Train set score: 0.968\n",
      "#Test set score: 0.768\n",
      "#Train set score: 0.971\n",
      "#Test set score: 0.793\n"
     ]
    }
   ],
   "source": [
    "# max_features 제한 X\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) \n",
    "print('#Train set dimension:', X_train_tfidf.shape) \n",
    "X_test_tfidf = tfidf.transform(X_test) \n",
    "print('#Test set dimension:', X_test_tfidf.shape)\n",
    "\n",
    "ridge_clf = RidgeClassifier(alpha=2.4)\n",
    "ridge_clf.fit(X_train_tfidf, y_train) \n",
    "print('#Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.01) \n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) \n",
    "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd496788",
   "metadata": {},
   "source": [
    "# N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cced356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 11483)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cachedStopWords = stopwords.words('english')\n",
    "tfidf = TfidfVectorizer(token_pattern = \"[a-zA-Z']{3,}\",\n",
    "                       decode_error = 'ignore',\n",
    "                       lowercase = True,\n",
    "                       stop_words = stopwords.words('english'),\n",
    "                       max_df = 0.5,\n",
    "                       min_df = 2)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb6e6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.976\n",
      "Test set score: 0.766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9168a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26541)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern = \"['a-zA-z']{3,}\",\n",
    "                       decode_error = 'ignore',\n",
    "                       lowercase = True,\n",
    "                       stop_words = stopwords.words('english'),\n",
    "                       ngram_range = (1, 2),\n",
    "                       max_df = 0.5,\n",
    "                       min_df = 2)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5636b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-gram samples:  [\"'cause can't\", \"'em better\", \"'expected errors'\", \"'karla' next\", \"'nodis' password\", \"'official doctrine\", \"'ok see\", \"'sci astro'\", \"'what's moonbase\", '[deletions] [deletions]']\n",
      "Train set score: 0.976\n",
      "Test set score: 0.769\n"
     ]
    }
   ],
   "source": [
    "bigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 1]\n",
    "print('bi-gram samples: ', bigram_features[:10])\n",
    "\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfaf21ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 32943)\n",
      "tri-gram samples: [\"'em better shots\", \"'expected errors' basically\", \"'karla' next one\", \"'nodis' password also\", \"'official doctrine think\", \"'ok see warning\", \"'what's moonbase good\", 'aas american astronautical', 'ability means infallible', 'able accept donations']\n",
      "Train set score: 0.976\n",
      "Test set score: 0.775\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", \n",
    "                        decode_error ='ignore', \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'),\n",
    "                        ngram_range=(1, 3),\n",
    "                        max_df=0.5,\n",
    "                        min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "trigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 2]\n",
    "print('tri-gram samples:', trigram_features[:10])\n",
    "\n",
    "ridge_clf.fit(X_train_tfidf, y_train) \n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2115f",
   "metadata": {},
   "source": [
    "# 한국어 문서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ca5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9057253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./daum_movie_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eed4311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f0e82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd0aac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size:  11043\n",
      "#Test set size:  3682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['title'], random_state = 0)\n",
    "\n",
    "print('#Train set size: ', len(X_train))\n",
    "print('#Test set size: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cbf9df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
      "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(X_train[1]))\n",
    "print(okt.nouns(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5821543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer = okt.nouns, max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd63fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.756\n",
      "#Test set score: 0.694\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter = 1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0737ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 영화 제목, 예측한 제목, 리뷰\n",
      "('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')\n",
      "('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')\n",
      "('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')\n",
      "('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')\n",
      "('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')\n",
      "('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')\n",
      "('신과함께', '신과함께', '잠만 자다 왔음')\n",
      "('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')\n",
      "('범죄도시', '신과함께', '잼남')\n",
      "('범죄도시', '인피니티 워', '대박~~')\n"
     ]
    }
   ],
   "source": [
    "print('실제 영화 제목, 예측한 제목, 리뷰')\n",
    "for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038acac",
   "metadata": {},
   "source": [
    "## 성능 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9697d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.777\n",
      "#Test set score: 0.695\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = okt.morphs, max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter = 1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe14f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text):\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm = True, stem = True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c0ecb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.784\n",
      "#Test set score: 0.712\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = twit_tokenizer, max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter = 1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f9dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입/Noun', '하다/Verb', '없다/Adjective', './Punctuation', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', './Punctuation', '내/Noun', '가/Josa', '전투/Noun', '에/Josa', '참여/Noun', '한/Determiner', '듯/Noun', '손/Noun', '에/Josa', '땀/Noun', '이남/Noun', './Punctuation']\n"
     ]
    }
   ],
   "source": [
    "# 동일 단어 품사 구분 가능하게\n",
    "def twit_tokenizer2(text):\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm = True, stem = True):\n",
    "        result.append('/'.join([word, tag]))\n",
    "    return result\n",
    "\n",
    "print(twit_tokenizer2(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54863a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.789\n",
      "#Test set score: 0.718\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = twit_tokenizer2, max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter = 1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b10e0",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7253b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37ecf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Max alpha 1.600 at max validation score 0.727\n"
     ]
    }
   ],
   "source": [
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
    "    X_train_tfidf, y_train, test_size = 0.2, random_state = 42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0.1, 10, 0.1):\n",
    "    ridge_clf = RidgeClassifier(alpha = alpha)\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge)\n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "\n",
    "print('#Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a036c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Ridge Train set score: 0.807\n",
      "#Ridge Test set score: 0.726\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha = 1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Ridge Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Ridge Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd87e419",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77df3610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Lasso Train set score: 0.703\n",
      "#Lasso Test set score: 0.696\n",
      "#Used features count: 957 out of 2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lasso_clf = LogisticRegression(penalty = 'l1', solver = 'liblinear', C = 0.5)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Lasso Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Lasso Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c2ac5",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb4ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.768\n",
      "Test set score: 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_clf = MultinomialNB(alpha = 0.1)\n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
