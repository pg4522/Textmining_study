{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff14e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 2034\n",
      "#Test set size: 1353\n",
      "#Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "#Train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train',\n",
    "                                          remove = ('headers', 'footers', 'quotes'),\n",
    "                                          categories = categories)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test',\n",
    "                                          remove = ('headers', 'footers', 'quotes'),\n",
    "                                          categories = categories)\n",
    "\n",
    "print('#Train set size:', len(newsgroups_train.data))\n",
    "print('#Test set size:', len(newsgroups_test.data))\n",
    "print('#Selected categories:', newsgroups_train.target_names)\n",
    "print('#Train labels:', set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73e500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "#Train set label smaples: 1\n",
      "#Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "#Test set label smaples: 2\n"
     ]
    }
   ],
   "source": [
    "print('#Train set text samples:', newsgroups_train.data[0])\n",
    "print('#Train set label smaples:', newsgroups_train.target[0])\n",
    "print('#Test set text samples:', newsgroups_test.data[0])\n",
    "print('#Test set label smaples:', newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b75fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension:  (2034, 2000)\n",
      "Test set dimension:  (1353, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "print('Train set dimension: ', X_train_cv.shape)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "print('Test set dimension: ', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74df22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(cv.get_feature_names_out()[:100], X_train_cv[0].toarray()[0, :100]):\n",
    "    print(word, ':', count, end = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c9720",
   "metadata": {},
   "source": [
    "# 나이브 베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26977532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.824\n",
      "Test set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train))) \n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a161973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
      "#Second document and label in test data: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n"
     ]
    }
   ],
   "source": [
    "print('#First document and label in test data:', X_test[0], y_test[0])\n",
    "print('#Second document and label in test data:', X_test[1], y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3388c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Predicted labels:  [2 1]\n",
      "#Predicted categories: sci.space comp.graphics\n"
     ]
    }
   ],
   "source": [
    "pred = NB_clf.predict(X_test_cv[:2])\n",
    "print('#Predicted labels: ', pred)\n",
    "print('#Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6189a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.862\n",
      "Test set score: 0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 2000, max_df = 0.5, min_df = 5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) \n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d28c9536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
      "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
      "sci.space: space, on, you, be, was, this, as, they, have, are\n",
      "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkw/opt/anaconda3/envs/serv1/lib/python3.7/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top10_features(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names_out())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(-classifier.coef_[i])[:10]\n",
    "        print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
    "        # coef_ -> 로지스틱 회귀 분석에서 주로 사용할 것, sklearn에서 더 이상 지원X\n",
    "top10_features(NB_clf, tfidf, newsgroups_train.target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
